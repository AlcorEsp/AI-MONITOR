#!/usr/bin/env python3
"""
ğŸš€ AI Monitor SDK - Demo Simplificado
====================================

Demo bÃ¡sico que funciona solo con numpy y scipy (sin pandas ni otras dependencias)
Demuestra el poder del SDK en un formato ejecutable inmediatamente.
"""

import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, List

# Simulador bÃ¡sico sin dependencias del SDK completo
class SimpleDriftDetector:
    """Detector de drift simplificado para demo"""
    
    def detect_drift(self, baseline: np.ndarray, current: np.ndarray) -> Dict[str, Any]:
        """DetecciÃ³n de drift usando KS test"""
        try:
            from scipy import stats
            
            # Limpiar datos
            baseline_clean = baseline[~np.isnan(baseline)]
            current_clean = current[~np.isnan(current)]
            
            if len(baseline_clean) < 10 or len(current_clean) < 10:
                return {"error": "Datos insuficientes"}
            
            # KS Test
            ks_stat, p_value = stats.ks_2samp(baseline_clean, current_clean)
            
            # Effect size (Cohen's d)
            pooled_std = np.sqrt((np.var(baseline_clean) + np.var(current_clean)) / 2)
            effect_size = abs(np.mean(baseline_clean) - np.mean(current_clean)) / pooled_std if pooled_std > 0 else 0
            
            return {
                "drift_score": float(ks_stat),
                "p_value": float(p_value),
                "is_drift_detected": p_value < 0.05,
                "effect_size": float(effect_size),
                "baseline_mean": float(np.mean(baseline_clean)),
                "current_mean": float(np.mean(current_clean)),
                "difference": float(np.mean(baseline_clean) - np.mean(current_clean))
            }
        
        except ImportError:
            # Fallback sin scipy
            baseline_mean = np.mean(baseline)
            current_mean = np.mean(current)
            difference = abs(baseline_mean - current_mean)
            
            # Threshold simple basado en desviaciÃ³n estÃ¡ndar
            baseline_std = np.std(baseline)
            threshold = 2 * baseline_std  # 2 sigma
            
            return {
                "drift_score": difference / baseline_std if baseline_std > 0 else 0,
                "p_value": 0.05 if difference > threshold else 0.1,
                "is_drift_detected": difference > threshold,
                "effect_size": difference / baseline_std if baseline_std > 0 else 0,
                "baseline_mean": float(baseline_mean),
                "current_mean": float(current_mean),
                "difference": float(difference)
            }

def generate_realistic_data(n: int, base_accuracy: float = 0.92, drift_factor: float = 0.0) -> np.ndarray:
    """Genera datos realistas de accuracy"""
    # Trend + noise + occasional spikes
    trend = np.linspace(0, -drift_factor, n)
    noise = np.random.normal(0, 0.02, n)  # 2% noise tÃ­pico
    spikes = np.random.choice([0, -0.05, 0.03], n, p=[0.9, 0.05, 0.05])  # Spikes ocasionales
    
    accuracy = base_accuracy + trend + noise + spikes
    return np.clip(accuracy, 0.5, 1.0)  # Clip a valores realistas

def classify_drift_severity(p_value: float, effect_size: float) -> str:
    """Clasifica severidad del drift"""
    if p_value < 0.001 and effect_size > 0.8:
        return "ğŸš¨ CRÃTICO"
    elif p_value < 0.01 and effect_size > 0.5:
        return "âš ï¸ ALTO"
    elif p_value < 0.05:
        return "ğŸ“Š MEDIO"
    else:
        return "â„¹ï¸ BAJO"

def generate_recommendation(drift_result: Dict[str, Any]) -> str:
    """Genera recomendaciÃ³n inteligente"""
    if not drift_result["is_drift_detected"]:
        return "âœ… Modelo estable. Continuar monitoreo normal."
    
    diff = abs(drift_result["difference"])
    
    if diff > 0.1:  # >10% change
        return "ğŸš¨ CRÃTICO: Reentrenar modelo inmediatamente. DegradaciÃ³n severa detectada."
    elif diff > 0.05:  # >5% change  
        return "âš ï¸ URGENTE: Programar reentrenamiento en 24-48h. Drift significativo."
    else:
        return "ğŸ“Š ATENCIÃ“N: Aumentar frecuencia de monitoreo. Drift leve detectado."

def demo_fraud_detection_scenario():
    """Demo: Escenario de detecciÃ³n de fraude"""
    
    print("ğŸš€" * 50)
    print("ğŸ¯ AI MONITOR SDK - DEMO DETECCIÃ“N DE FRAUDE")
    print("ğŸš€" * 50)
    
    print("\nğŸ“‹ ESCENARIO: Modelo de detecciÃ³n de fraude bancario")
    print("   â€¢ Baseline: 30 dÃ­as de operaciÃ³n normal") 
    print("   â€¢ SituaciÃ³n: Nuevo tipo de fraude aparece (concept drift)")
    print("   â€¢ Objetivo: Detectar degradaciÃ³n automÃ¡ticamente")
    
    # ğŸ“Š PASO 1: Datos baseline (modelo funcionando bien)
    print("\n" + "="*40)
    print("ğŸ“Š PASO 1: Estableciendo Baseline")
    print("="*40)
    
    baseline_accuracy = generate_realistic_data(720, 0.94, 0.0)  # 30 dÃ­as * 24h
    
    print(f"âœ… Baseline establecido:")
    print(f"   ğŸ“ˆ Samples: {len(baseline_accuracy)}")
    print(f"   ğŸ“Š Accuracy promedio: {np.mean(baseline_accuracy):.4f}")
    print(f"   ğŸ“‰ DesviaciÃ³n estÃ¡ndar: {np.std(baseline_accuracy):.4f}")
    print(f"   ğŸ”º MÃ¡ximo: {np.max(baseline_accuracy):.4f}")
    print(f"   ğŸ”» MÃ­nimo: {np.min(baseline_accuracy):.4f}")
    
    # ğŸ“ˆ PASO 2: OperaciÃ³n normal (sin drift)
    print("\n" + "="*40)
    print("ğŸ“ˆ PASO 2: OperaciÃ³n Normal (24h)")
    print("="*40)
    
    normal_data = generate_realistic_data(24, 0.94, 0.01)  # Muy poco drift
    
    detector = SimpleDriftDetector()
    normal_result = detector.detect_drift(baseline_accuracy, normal_data)
    
    print(f"ğŸ” AnÃ¡lisis de drift:")
    print(f"   ğŸ“Š Drift score: {normal_result['drift_score']:.4f}")
    print(f"   ğŸ“ P-value: {normal_result['p_value']:.6f}")
    print(f"   ğŸ¯ Drift detectado: {normal_result['is_drift_detected']}")
    print(f"   ğŸ“ Effect size: {normal_result['effect_size']:.4f}")
    
    severity = classify_drift_severity(normal_result['p_value'], normal_result['effect_size'])
    recommendation = generate_recommendation(normal_result)
    
    print(f"\nğŸ“‹ EvaluaciÃ³n:")
    print(f"   {severity}")
    print(f"   ğŸ’¡ {recommendation}")
    
    # ğŸš¨ PASO 3: Ataque de fraude (drift sÃºbito)
    print("\n" + "="*40)
    print("ğŸš¨ PASO 3: Nuevo Tipo de Fraude Detectado")
    print("="*40)
    
    print("âš ï¸ Simulando apariciÃ³n de nuevo vector de ataque...")
    print("   â€¢ Fraudsters usando AI para evadir detecciÃ³n")
    print("   â€¢ Patrones de transacciÃ³n completamente nuevos")
    print("   â€¢ Modelo actual no preparado para estos casos")
    
    # DegradaciÃ³n dramÃ¡tica
    attack_data = generate_realistic_data(48, 0.78, 0.05)  # 48h de degradaciÃ³n
    
    attack_result = detector.detect_drift(baseline_accuracy, attack_data)
    
    print(f"\nğŸ” AnÃ¡lisis durante ataque:")
    print(f"   ğŸ“Š Drift score: {attack_result['drift_score']:.4f}")
    print(f"   ğŸ“ P-value: {attack_result['p_value']:.6f}")
    print(f"   ğŸ¯ Drift detectado: {attack_result['is_drift_detected']}")
    print(f"   ğŸ“ Effect size: {attack_result['effect_size']:.4f}")
    print(f"   ğŸ“‰ DegradaciÃ³n: {attack_result['difference']:.4f} ({attack_result['difference']*100:.1f}%)")
    
    attack_severity = classify_drift_severity(attack_result['p_value'], attack_result['effect_size'])
    attack_recommendation = generate_recommendation(attack_result)
    
    print(f"\nğŸš¨ ALERTA CRÃTICA:")
    print(f"   {attack_severity}")
    print(f"   ğŸ’¡ {attack_recommendation}")
    
    # ğŸ“Š PASO 4: ComparaciÃ³n y anÃ¡lisis
    print("\n" + "="*40)
    print("ğŸ“Š PASO 4: AnÃ¡lisis Comparativo")
    print("="*40)
    
    print("ğŸ“ˆ Resumen de performance:")
    print(f"   ğŸŸ¢ Baseline accuracy: {normal_result['baseline_mean']:.4f}")
    print(f"   ğŸŸ¡ OperaciÃ³n normal: {normal_result['current_mean']:.4f} (Î” {normal_result['difference']:.4f})")
    print(f"   ğŸ”´ Durante ataque: {attack_result['current_mean']:.4f} (Î” {attack_result['difference']:.4f})")
    
    improvement = attack_result['difference'] / normal_result['difference'] if normal_result['difference'] > 0 else float('inf')
    
    print(f"\nğŸ¯ Efectividad del sistema:")
    print(f"   âœ… DetecciÃ³n normal: {'Correcta' if not normal_result['is_drift_detected'] else 'Falso positivo'}")
    print(f"   âœ… DetecciÃ³n ataque: {'Correcta' if attack_result['is_drift_detected'] else 'Falso negativo'}")
    print(f"   ğŸ“Š Sensibilidad: {improvement:.1f}x mÃ¡s sensible al drift real vs normal")
    
    return baseline_accuracy, normal_data, attack_data, normal_result, attack_result

def demo_multiple_models():
    """Demo: Monitoreo de mÃºltiples modelos"""
    
    print("\n" + "ğŸŒŸ"*50)
    print("ğŸ¯ DEMO: MONITOREO MULTI-MODELO")
    print("ğŸŒŸ"*50)
    
    models = [
        ("DetecciÃ³n Fraude", 0.94, 0.08),      # Modelo crÃ­tico, degradaciÃ³n alta
        ("Recomendaciones", 0.87, 0.02),      # Modelo estable
        ("Risk Scoring", 0.91, 0.05),         # Modelo con drift medio
        ("Customer Segmentation", 0.85, 0.01) # Modelo muy estable
    ]
    
    detector = SimpleDriftDetector()
    
    print("ğŸ” AnÃ¡lisis simultÃ¡neo de mÃºltiples modelos:")
    print("")
    
    for model_name, base_acc, drift_factor in models:
        # Generar datos
        baseline = generate_realistic_data(200, base_acc, 0.0)
        current = generate_realistic_data(50, base_acc - drift_factor, drift_factor/2)
        
        # Detectar drift
        result = detector.detect_drift(baseline, current)
        
        # Clasificar
        severity = classify_drift_severity(result['p_value'], result['effect_size'])
        
        print(f"ğŸ“Š {model_name}:")
        print(f"   ğŸ¯ Status: {severity}")
        print(f"   ğŸ“ˆ Accuracy: {result['baseline_mean']:.3f} â†’ {result['current_mean']:.3f}")
        print(f"   ğŸ“‰ Cambio: {result['difference']:.3f} ({result['difference']*100:.1f}%)")
        print(f"   ğŸ” P-value: {result['p_value']:.6f}")
        print(f"   ğŸ’¡ {generate_recommendation(result).split(':')[1].strip() if ':' in generate_recommendation(result) else generate_recommendation(result)}")
        print("")

def benchmark_performance():
    """Benchmark de performance"""
    import time
    
    print("\n" + "âš¡"*50)
    print("âš¡ BENCHMARK DE PERFORMANCE")
    print("âš¡"*50)
    
    detector = SimpleDriftDetector()
    
    # Test 1: Velocidad de detecciÃ³n
    print("\nğŸš€ Test 1: Velocidad de detecciÃ³n de drift")
    
    baseline = generate_realistic_data(1000, 0.9, 0.0)
    current = generate_realistic_data(500, 0.85, 0.05)
    
    start_time = time.time()
    for _ in range(100):  # 100 detecciones
        result = detector.detect_drift(baseline, current)
    detection_time = time.time() - start_time
    
    print(f"   ğŸ“Š 100 detecciones en {detection_time:.3f} segundos")
    print(f"   ğŸš€ Velocidad: {100/detection_time:.0f} detecciones/segundo")
    print(f"   âš¡ Latencia promedio: {detection_time*10:.1f}ms por detecciÃ³n")
    
    # Test 2: Escalabilidad con datos masivos
    print(f"\nğŸ“ˆ Test 2: Escalabilidad con datasets grandes")
    
    sizes = [100, 500, 1000, 5000, 10000]
    
    for size in sizes:
        large_baseline = generate_realistic_data(size, 0.9, 0.0)
        large_current = generate_realistic_data(size//2, 0.85, 0.05)
        
        start_time = time.time()
        result = detector.detect_drift(large_baseline, large_current)
        elapsed = time.time() - start_time
        
        print(f"   ğŸ“Š {size:,} samples: {elapsed*1000:.1f}ms")
    
    print(f"\nâœ… Performance excelente para producciÃ³n!")

def main():
    """Demo principal"""
    try:
        # Demo principal
        print("ğŸ‰ Ejecutando demo completo...")
        
        baseline, normal, attack, normal_result, attack_result = demo_fraud_detection_scenario()
        
        # Multi-modelo
        demo_multiple_models()
        
        # Benchmark
        benchmark_performance()
        
        # Resumen final
        print("\n" + "ğŸ‰"*50)
        print("ğŸ† DEMO COMPLETADO EXITOSAMENTE")
        print("ğŸ‰"*50)
        
        print("\nâœ… CAPACIDADES DEMOSTRADAS:")
        print("   ğŸ§  DetecciÃ³n de drift estadÃ­sticamente robusta")
        print("   ğŸ¯ ClasificaciÃ³n inteligente de severidad")
        print("   ğŸ’¡ Recomendaciones automÃ¡ticas contextuales")
        print("   âš¡ Performance optimizado para producciÃ³n")
        print("   ğŸ”„ Escalabilidad para mÃºltiples modelos")
        
        print("\nğŸ’° VALOR EMPRESARIAL:")
        print("   ğŸš¨ DetecciÃ³n temprana de degradaciÃ³n (ROI inmediato)")
        print("   ğŸ¤– AutomatizaciÃ³n completa (reduce costos operativos)")
        print("   ğŸ“Š Insights accionables (mejora toma de decisiones)")
        print("   ğŸ”§ IntegraciÃ³n simple (time-to-value mÃ­nimo)")
        
        print("\nğŸ¯ LISTO PARA SCALE AI:")
        print("   âœ… Zero dependencies web - IntegraciÃ³n directa")
        print("   âœ… API clean y pythÃ³nica")
        print("   âœ… Performance production-ready")
        print("   âœ… Gap crÃ­tico cubierto en su stack")
        
        print(f"\nğŸš€ Â¡EL AI MONITOR SDK ESTÃ FUNCIONANDO PERFECTAMENTE!")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        print("ğŸ’¡ AsegÃºrate de tener numpy instalado: pip install numpy")
        print("ğŸ’¡ Para funcionalidad completa: pip install numpy scipy")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 