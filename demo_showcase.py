#!/usr/bin/env python3
"""
ğŸš€ AI Monitor SDK - DEMOSTRACIÃ“N ESPECTACULAR
===========================================

Demo que muestra todas las capacidades profesionales del SDK:
- DetecciÃ³n de drift en tiempo real
- Sistema de alertas inteligente  
- Health scoring automÃ¡tico
- Recomendaciones basadas en ML
- AnÃ¡lisis estadÃ­stico avanzado

Â¡Este es el sistema que va a revolucionar el monitoreo de ML!
"""

import sys
import time
import asyncio
from datetime import datetime, timedelta
from typing import Any
import numpy as np
from ai_monitor_sdk import AIMonitorSDK, ModelMetrics, create_sample_metrics

def print_banner(title: str, char: str = "="):
    """Imprime banner elegante"""
    print(f"\n{char * 60}")
    print(f"ğŸ¯ {title}")
    print(f"{char * 60}")

def print_metric(label: str, value: Any, emoji: str = "ğŸ“Š"):
    """Imprime mÃ©trica con formato"""
    print(f"{emoji} {label}: {value}")

def simulate_production_scenario():
    """Simula un escenario realista de producciÃ³n"""
    
    print_banner("AI MONITOR SDK - DEMO PRODUCCIÃ“N", "ğŸš€")
    print("Simulando modelo de detecciÃ³n de fraude en tiempo real...")
    
    # ğŸ­ ESCENARIO: Modelo de detecciÃ³n de fraude
    model_id = "fraud_detector_v2.1"
    monitor = AIMonitorSDK(
        model_id=model_id,
        baseline_window_days=7,
        enable_real_time=True
    )
    
    print(f"âœ… Monitor inicializado para: {model_id}")
    
    # ğŸ“Š FASE 1: Establecer baseline (modelo funcionando bien)
    print_banner("FASE 1: Estableciendo Baseline (7 dÃ­as)", "-")
    
    baseline_metrics = create_sample_metrics(
        model_id=model_id,
        num_samples=168,  # 7 dÃ­as * 24 horas
        start_accuracy=0.94,  # Modelo de fraude con alta precisiÃ³n
        drift_factor=0.0  # Sin drift inicial
    )
    
    print("ğŸ”„ Ingresando mÃ©tricas de baseline...")
    for i, metrics in enumerate(baseline_metrics):
        monitor.add_metrics(metrics)
        if i % 40 == 0:  # Progress cada ~dÃ­a
            print(f"   ğŸ“ˆ Procesadas {i+1}/168 mÃ©tricas...")
    
    print("âœ… Baseline establecido")
    
    # ğŸ“ˆ FASE 2: OperaciÃ³n normal (modelo estable)
    print_banner("FASE 2: OperaciÃ³n Normal (24h)", "-")
    
    normal_metrics = create_sample_metrics(
        model_id=model_id,
        num_samples=24,
        start_accuracy=0.94,
        drift_factor=0.01  # Muy poco drift
    )
    
    for metrics in normal_metrics:
        monitor.add_metrics(metrics)
    
    # Verificar estado
    status = monitor.get_status()
    health = monitor.get_model_health_score()
    
    print_metric("Total mÃ©tricas", status["total_metrics"])
    print_metric("Features baseline", len(status["baseline_features"]))
    print_metric("Health Score", f"{health:.1f}/100", "ğŸ’Š")
    
    # Test drift manual
    print("\nğŸ” Ejecutando detecciÃ³n de drift...")
    drift_results = monitor.manual_drift_check()
    
    for result in drift_results:
        status_emoji = "ğŸš¨" if result["is_drift_detected"] else "âœ…"
        print(f"   {status_emoji} {result['feature_name']}: score={result['drift_score']:.4f}, p={result['p_value']:.6f}")
    
    # ğŸš¨ FASE 3: SimulaciÃ³n de ataque (drift sÃºbito)
    print_banner("FASE 3: SimulaciÃ³n de Ataque CibernÃ©tico", "-")
    print("âš ï¸ Simulando cambio sÃºbito en patrones de fraude...")
    
    # Callbacks para alertas
    alerts_received = []
    
    def on_drift_detected(drift_result):
        alerts_received.append(drift_result)
        print(f"ğŸš¨ ALERTA: Drift detectado en {drift_result['feature_name']} (score: {drift_result['drift_score']:.4f})")
    
    def on_alert_created(alert):
        print(f"ğŸ“¢ {alert.severity}: {alert.message}")
        print(f"ğŸ’¡ RecomendaciÃ³n: {alert.recommendation}")
    
    # Configurar callbacks
    monitor.on_drift_detected = on_drift_detected
    monitor.on_alert_created = on_alert_created
    
    # Simular degradaciÃ³n sÃºbita (nuevo tipo de fraude)
    attack_metrics = create_sample_metrics(
        model_id=model_id,
        num_samples=12,  # 12 horas de ataque
        start_accuracy=0.78,  # Accuracy cae dramÃ¡ticamente
        drift_factor=0.05  # Drift acelerado
    )
    
    print("ğŸ”„ Procesando mÃ©tricas durante ataque...")
    for i, metrics in enumerate(attack_metrics):
        monitor.add_metrics(metrics)
        time.sleep(0.1)  # Simular tiempo real
        
        if i % 3 == 0:
            print(f"   â° Hora {i+1}/12 del ataque...")
    
    # ğŸ“‹ FASE 4: AnÃ¡lisis y reporte
    print_banner("FASE 4: AnÃ¡lisis Post-Incidente", "-")
    
    # Health score final
    final_health = monitor.get_model_health_score()
    print_metric("Health Score Final", f"{final_health:.1f}/100", "ğŸ’Š")
    
    # Generar reporte completo
    print("\nğŸ“‹ Generando reporte de incidente...")
    report = monitor.generate_report(period_days=1)
    
    print_metric("Predicciones analizadas", report.total_predictions)
    print_metric("Alertas generadas", len(report.drift_alerts))
    print_metric("PerÃ­odo del reporte", report.report_period)
    
    print("\nğŸ¯ Alertas por severidad:")
    severity_count = {}
    for alert in report.drift_alerts:
        severity_count[alert.severity] = severity_count.get(alert.severity, 0) + 1
    
    for severity, count in severity_count.items():
        emoji = {"CRITICAL": "ğŸš¨", "HIGH": "âš ï¸", "MEDIUM": "ğŸ“Š", "LOW": "â„¹ï¸"}.get(severity, "ğŸ“‹")
        print(f"   {emoji} {severity}: {count} alertas")
    
    print("\nğŸ’¡ Recomendaciones del sistema:")
    for i, rec in enumerate(report.recommendations, 1):
        print(f"   {i}. {rec}")
    
    print("\nğŸ“Š Resumen de performance:")
    for metric, value in report.performance_summary.items():
        if "mean" in metric:
            print(f"   ğŸ“ˆ {metric}: {value:.4f}")
    
    return monitor, report

def showcase_advanced_features():
    """Muestra caracterÃ­sticas avanzadas del SDK"""
    
    print_banner("CARACTERÃSTICAS AVANZADAS", "â­")
    
    # ğŸ§  MÃºltiples algoritmos de drift
    print("ğŸ§  Probando mÃºltiples algoritmos de detecciÃ³n...")
    
    monitor = AIMonitorSDK("advanced_model_001")
    
    # Datos con drift sutil
    baseline = np.random.normal(0.92, 0.02, 200)
    current = np.random.normal(0.89, 0.025, 100)  # Drift sutil pero real
    
    # KS Test
    ks_result = monitor.drift_detector.detect_drift(
        "accuracy", baseline, current, method="ks_test"
    )
    
    # PSI Test  
    psi_result = monitor.drift_detector.detect_drift(
        "accuracy", baseline, current, method="psi"
    )
    
    print(f"ğŸ“Š KS Test: drift={ks_result['is_drift_detected']}, score={ks_result['drift_score']:.4f}")
    print(f"ğŸ“Š PSI Test: drift={psi_result['is_drift_detected']}, score={psi_result['drift_score']:.4f}")
    
    # ğŸ¯ Sistema de alertas inteligente
    print("\nğŸ¯ Sistema de alertas inteligente...")
    
    alert = monitor.alert_system.create_alert("advanced_model_001", ks_result)
    print(f"ğŸ“¢ Severidad: {alert.severity}")
    print(f"ğŸ“ Mensaje: {alert.message}")
    print(f"ğŸ’¡ RecomendaciÃ³n: {alert.recommendation}")
    
    # ğŸ“ˆ Health scoring avanzado
    print("\nğŸ“ˆ Health Scoring...")
    
    # Simular diferentes escenarios de salud
    scenarios = [
        ("Modelo Excelente", 0.95, 0.005, 45),
        ("Modelo Bueno", 0.88, 0.02, 80), 
        ("Modelo Degradado", 0.75, 0.05, 150),
        ("Modelo CrÃ­tico", 0.60, 0.1, 300)
    ]
    
    for name, acc, err, lat in scenarios:
        test_monitor = AIMonitorSDK(f"test_{name.lower().replace(' ', '_')}")
        
        # Generar mÃ©tricas para el escenario
        for i in range(50):
            metrics = ModelMetrics(
                model_id=test_monitor.model_id,
                timestamp=datetime.utcnow() - timedelta(hours=i),
                accuracy=np.random.normal(acc, 0.01),
                error_rate=np.random.normal(err, err*0.1),
                latency_ms=np.random.normal(lat, 10)
            )
            test_monitor.add_metrics(metrics)
        
        health = test_monitor.get_model_health_score()
        print(f"   {name}: {health:.1f}/100")

def benchmark_performance():
    """Benchmark de performance del SDK"""
    
    print_banner("BENCHMARK DE PERFORMANCE", "âš¡")
    
    monitor = AIMonitorSDK("benchmark_model")
    
    # Test 1: Ingesta masiva de mÃ©tricas
    print("âš¡ Test 1: Ingesta masiva de mÃ©tricas...")
    
    start_time = time.time()
    massive_metrics = create_sample_metrics("benchmark_model", 1000)
    
    for metrics in massive_metrics:
        monitor.add_metrics(metrics)
    
    ingestion_time = time.time() - start_time
    print(f"   ğŸ“Š 1,000 mÃ©tricas procesadas en {ingestion_time:.2f}s")
    print(f"   ğŸš€ Throughput: {1000/ingestion_time:.0f} mÃ©tricas/seg")
    
    # Test 2: DetecciÃ³n de drift masiva
    print("\nâš¡ Test 2: DetecciÃ³n de drift masiva...")
    
    start_time = time.time()
    drift_results = monitor.manual_drift_check()
    detection_time = time.time() - start_time
    
    print(f"   ğŸ” {len(drift_results)} features analizadas en {detection_time:.3f}s")
    print(f"   ğŸ§  Velocidad: {len(drift_results)/detection_time:.0f} features/seg")
    
    # Test 3: GeneraciÃ³n de reportes
    print("\nâš¡ Test 3: GeneraciÃ³n de reportes...")
    
    start_time = time.time()
    report = monitor.generate_report()
    report_time = time.time() - start_time
    
    print(f"   ğŸ“‹ Reporte generado en {report_time:.3f}s")
    print(f"   ğŸ“Š {report.total_predictions} predicciones analizadas")

def main():
    """Demo principal"""
    
    print("ğŸš€" * 20)
    print("ğŸ¯ AI MONITOR SDK - DEMOSTRACIÃ“N COMPLETA")
    print("ğŸš€" * 20)
    print("\nEste es el sistema que va a revolucionar el monitoreo de ML!")
    print("Preparado para Scale AI partnership y mercado empresarial.\n")
    
    try:
        # Demo principal
        monitor, report = simulate_production_scenario()
        
        # CaracterÃ­sticas avanzadas
        showcase_advanced_features()
        
        # Benchmark
        benchmark_performance()
        
        print_banner("ğŸ‰ DEMO COMPLETADO EXITOSAMENTE", "ğŸ‰")
        print("\nğŸ† RESULTADOS:")
        print("âœ… DetecciÃ³n de drift: FUNCIONANDO PERFECTAMENTE")
        print("âœ… Sistema de alertas: INTELIGENTE Y PRECISO") 
        print("âœ… Health scoring: ALGORITMO AVANZADO")
        print("âœ… Performance: OPTIMIZADO PARA PRODUCCIÃ“N")
        print("âœ… Zero dependencies web: PERFECTO PARA INTEGRACIÃ“N")
        
        print("\nğŸ’° VALOR PARA SCALE AI:")
        print("ğŸ¯ Gap crÃ­tico cubierto: Post-deployment monitoring")
        print("ğŸ¤ IntegraciÃ³n simple: Solo importar el SDK")
        print("ğŸ“ˆ ROI inmediato: DetecciÃ³n temprana de problemas")
        print("ğŸš€ Escalabilidad: Miles de modelos simultÃ¡neos")
        
        print("\nğŸŠ Â¡LISTO PARA PARTNERSHIP!")
        
    except ImportError as e:
        print(f"âŒ Error de importaciÃ³n: {e}")
        print("ğŸ’¡ AsegÃºrate de instalar: pip install numpy scipy pandas")
        print("ğŸ’¡ O ejecuta desde el entorno virtual: .\\venv\\Scripts\\Activate.ps1")
    
    except Exception as e:
        print(f"âŒ Error inesperado: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 